{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxIfMIy2iKnEPM/MEfsMxG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4a1ff0d5bdb4ffca4d4dd651f28bc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_bc374d29950045c1a60e49f10ed5d1f2",
            "metadata": [
              {
                "name": "2010-kodiak-bear-1.jpg",
                "type": "image/jpeg",
                "size": 216772,
                "lastModified": 1729414429158
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_07d2c6cd3f604652aa2834121160cc99"
          }
        },
        "bc374d29950045c1a60e49f10ed5d1f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07d2c6cd3f604652aa2834121160cc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Firojpaudel/Machine-Learning-Notes/blob/main/Chapter1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification : Cats and Dogs <br>\n",
        "<i>>> The first course project and its breakdown.</i>"
      ],
      "metadata": {
        "id": "e4TqJxltesK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "path = untar_data(URLs.PETS)/'images'\n",
        "\n",
        "def is_cat(x): return x[0].isupper()\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224)\n",
        ")\n",
        "\n",
        "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
        "# learn.fine_tune(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "AqG7Bb3LmIMK",
        "outputId": "4ad940fe-b483-483a-ea1c-a131a9fd8ab2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='811712512' class='' max='811706944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [811712512/811706944 00:22&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:01<00:00, 73.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "uploader = widgets.FileUpload()\n"
      ],
      "metadata": {
        "id": "pphNiuH10obP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(uploader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b4a1ff0d5bdb4ffca4d4dd651f28bc5b",
            "bc374d29950045c1a60e49f10ed5d1f2",
            "07d2c6cd3f604652aa2834121160cc99"
          ]
        },
        "id": "hd7ZOnlcI8NB",
        "outputId": "8570148b-8e60-45bd-8f60-aa5cae1f3ada"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4a1ff0d5bdb4ffca4d4dd651f28bc5b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image inserted here was:\n",
        "<div style=\"text-align: center;\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/2010-kodiak-bear-1.jpg/1200px-2010-kodiak-bear-1.jpg\" alt=\"A bear\" width=\"300\" height=\"200\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "GHdo7G37JOQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "from PIL import Image\n",
        "\n",
        "img = PILImage.create(uploader.data[0])\n",
        "is_cat,_,probs = learn.predict(img)\n",
        "print(f\"Is this a cat?: {is_cat}.\")\n",
        "print(f\"Probability it's a cat: {probs[1].item():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "um-HmUvh14W_",
        "outputId": "338284b6-cfb4-4012-9ab7-942362a4e031"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is this a cat?: False.\n",
            "Probability it's a cat: 0.462523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Breakdown of how this code works:"
      ],
      "metadata": {
        "id": "SKw1idZKaL8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The first line:\n",
        "from fastai.vision.all import *"
      ],
      "metadata": {
        "id": "PLFMrSeMis0z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line imports al the fastai.vision library. This gives us all the functions and classes we will need to create a wide variety of computer vision models."
      ],
      "metadata": {
        "id": "H4PQRwkPizbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The second line:\n",
        "path  = untar_data(URLs.PETS)/'images'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "BL9I84nzjM7z",
        "outputId": "498de32b-68ef-41cc-ba53-d354d1466e57"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='811712512' class='' max='811706944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [811712512/811706944 00:35&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line downloads a standard dataset from the fast.ai datasets collection and returns to the variabke named as \"path\""
      ],
      "metadata": {
        "id": "bY3dBro4jX2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The function part:\n",
        "def is_cat(x): return x[0].isupper()"
      ],
      "metadata": {
        "id": "WJnkLcvojn9y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "so here, we define a funtion is_cat that labels cats based on filename rule provided by dataset creators."
      ],
      "metadata": {
        "id": "eFBeCIG5tfWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#then we prepare the dataloader using the fast.ai functions as:\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct= 0.2, seed=42, label_func=is_cat, item_tfms=Resize(224)\n",
        ")"
      ],
      "metadata": {
        "id": "tE6ylZEYuBWg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here, the dataloader we created works as following:\n",
        "The ```.from_name_func``` is the method from fast.ai library which we use genreally for ImageDataLoaders. Then, ```path``` is the path we specified above. Similarly, ```get_image_files()``` is the function that retrieves all images files from the specified path. Then comes ```valid_pct``` which is simply setting aside 20% of the data for validation. Likewise, ```seed``` is used to ensure reproducibility by setting a random seed. And finally, ```item_tmfs = Resize(224)``` applies a transformation to resize all images to 224×224 pixels."
      ],
      "metadata": {
        "id": "t_nBTK0Xwu3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary><b>Why 224 pixels? </b><i> (click to view)</i></summary>\n",
        "- It is the standard size for historical reasons. Old pretrained models require this size exactly.\n",
        "But, we can pass pretty much anything.\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "F-fZoEFayJtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary><b>Why validation set? And how is effects in accuracy if we use trainset instead?</b></summary>\n",
        "- Having a validation set is crtitical. Because if we train the large enough model for long amount of time, the model will eventually memorize the label every time in our dataset. And will completely overfit. So we test the accuracy in unseen data by splitting the dataset to train and validation sets.\n",
        "</details>"
      ],
      "metadata": {
        "id": "GZcPJC9rzGEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<i> Slight note: fast.ai has by default ```valid_pct``` set to 0.2 so that even if we forget to add it in, fast.ai does that for us.</i>"
      ],
      "metadata": {
        "id": "5_kQdrSl7OVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#learning part:\n",
        "learn = cnn_learner(dls, resnet34, metrics= error_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akEDknW78wNF",
        "outputId": "ba29fe93-0bc9-47b2-d925-223e6b1fbc53"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/vision/learner.py:303: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n",
            "  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 142MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, this line of code simply is for deep learning. Here, we have the ```cnn_learner()``` funtion that is the function in fast.ai for cnn architecture.\n",
        "\n",
        "Then, we pass the dataloader we created earlier as its first parameter. Then the specific cnn architecture we would prefer. We're using ```resnet32``` here. And, the metric which we are calculating.\n",
        "\n",
        "<i> We are calculating error_rate in this exercise.</i>"
      ],
      "metadata": {
        "id": "R89AzjrA8_hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>What is Resnet34? And what is 34 here?</b>\n",
        "  </summary>\n",
        "- Resnet is the more refined CNN architecure that we use for image datasets. The \"34\" here stands for layers. <br>\n",
        "- Other variants include 18, 50, 101, 152.<br>\n",
        "- Models using more layers take longer to train and are more prone to overfitting.\n",
        "</details>"
      ],
      "metadata": {
        "id": "bsR6toV696m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Then last line:\n",
        "learn.fine_tune(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "FRIsZMxg-9wD",
        "outputId": "50ff0c11-5324-4310-ffa4-46ff489bcc63"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.169304</td>\n",
              "      <td>0.021718</td>\n",
              "      <td>0.006089</td>\n",
              "      <td>00:50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.063684</td>\n",
              "      <td>0.016792</td>\n",
              "      <td>0.005413</td>\n",
              "      <td>00:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's it doing? Just fitting into the ```learn``` model we just created. Or lets say finetuning. Here 1 stands for number of epochs which in this case is 1."
      ],
      "metadata": {
        "id": "EGjuRyqmBE_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>But why call fine_tune, and not fit? </b>\n",
        "  </summary>\n",
        "- fastai does have the <code>fit</code> method which looks at images in the training set multiple times, each time updating the parameters to make predictions closer and closer to target labels.<br>\n",
        "- But in this case, we have started with a pretrained model, and we dont want to throw away its capabilities. And this method is called as <b><i>finetuning</i></b>\n",
        "</details>"
      ],
      "metadata": {
        "id": "Sx9dJ6iBBpS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>What is a metric? And how does it differ from loss?</b>\n",
        "  </summary>\n",
        "- Loss is a measure of how well the model's predictions match the actual target values. Major purpose of loss is to guide the training process.\n",
        "<br>\n",
        "<br>\n",
        "- Metrics are used to evaluate the performance of model in a way that is more interpretable and relevant to specific problem. Used to assess the quality of model's predictions and are often used for model evaluation and comparison.\n",
        "</details>"
      ],
      "metadata": {
        "id": "Csj8SgX4MWxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>What is the \"head\" of the model?</b>\n",
        "  </summary>\n",
        "- It refers to the final layer or the layers that produce the output predictions. It's the part of model that directly interacts with the task-specific data, such as classification labels or regression values.\n",
        "</details>"
      ],
      "metadata": {
        "id": "KU4QtrrjNxMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<Details>\n",
        "  <summary>\n",
        "    <b>\n",
        "      What kinds of features do the early layers of a CNN find? How about the later layers?\n",
        "    </b>\n",
        "  </summary>\n",
        "- <b>Early layers:</b> These layers typically detect the patterns such as edges, lines and textures. They focus on low-level features and are the fundamental building blocks of the image.\n",
        "<br>\n",
        "- <b>Later Layers:</b> These layers combine the basic features detected by the earlier layers to identify more complex patterns and structures.  \n",
        "</Details>"
      ],
      "metadata": {
        "id": "udxHVjVXOo6w"
      }
    }
  ]
}