{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Firojpaudel/Machine-Learning-Notes/blob/main/Practical%20Deep%20Learning%20For%20Coders/Chapter_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiLabel Classification And Regression"
      ],
      "metadata": {
        "id": "6Apt4iXyvuWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the last chapter, we learned some practical tips for training models, like choosing the right learning rates and number of epochs which were really important for good results. Now, this chapter dives into two new types of computer vision problems: multi-label classification (predicting multiple labels for an image or none at all) and regression (predicting numbers instead of categories). Along the way, we'll explore output activations, targets, and loss functions in more depth."
      ],
      "metadata": {
        "id": "Y0KrC4hY5bUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MultiLabel Classification"
      ],
      "metadata": {
        "id": "cY0RDWJU6s-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*MultiLabel Classification* refers to the problem of identifying the objects in images that may not contain exactly one type of object.\n",
        "\n",
        "There may be more than one type of object or there may be none.\n",
        "\n",
        "In previous bear classifier we built, it had no ability to predict \"not bear at all\". So, this time we are trying to fix that.\n",
        "\n",
        "First, let's see what a mutilabel dataset looks like. But before that lets set up the notebook."
      ],
      "metadata": {
        "id": "0VrYTbeO6zvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Setting up the notebook\n",
        "##@ Notebook initialization\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "##@ Installing dependencies\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "\n",
        "##@ Importing the necessary libraries\n",
        "from fastbook import *\n",
        "from fastai.callback.fp16 import *\n",
        "from fastai.vision.all import *"
      ],
      "metadata": {
        "id": "zmW6nLKS8BOl",
        "outputId": "0e23275f-42ca-40ef-fa81-afda5ffa2f68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/719.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Data"
      ],
      "metadata": {
        "id": "aPHFclorJ3An"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will get the PASCAL datset which has more than one kind of classified object per image."
      ],
      "metadata": {
        "id": "dyCqVFRz9FRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Getting the PASCAL dataset\n",
        "path = untar_data(URLs.PASCAL_2007)\n",
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ZTkQyd_J-bwd",
        "outputId": "c017e81b-789f-4332-de9c-bf2f60928b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='487792640' class='' max='1637796771' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      29.78% [487792640/1637796771 04:58&lt;11:42]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><b>More about this dataset:</b></summary>\n",
        "This dataset is a bit different from the ones we've worked with before. Instead of being organized by filenames or folders, it comes with a CSV file that tells us which labels to use for each image.\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "F0N9NtNK-lk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ inspecting the dataset\n",
        "df = pd.read_csv(path/'train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SB5fXHtP_KH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "header = \"\"\"\n",
        "===============================================================\n",
        "                Pandas and DataFrames Subsection in Book\n",
        "===============================================================\n",
        "\"\"\"\n",
        "print(header)\n",
        "\n",
        "# Accessing rows and columns using .iloc\n",
        "print(\"------- Using .iloc: -------\")\n",
        "print(f\"Returning the 1st column of the dataframe:\\n\\n{df.iloc[:, 0]} \\n\")  # 1st column (labels)\n",
        "print(f\"Returning the 1st row of the dataframe:\\n\\n{df.iloc[0, :]} \\n\")    # 1st row (details of item1)\n",
        "\n",
        "# Grabbing a column by name (without using iloc)\n",
        "print(f\"Grabbing the column 'labels' directly from the dataframe:\\n\\n{df['labels']}\\n\\n\")\n",
        "\n",
        "# Calculations in the dataframe\n",
        "print(\"----- Calculations in the DataFrame itself ------ \\n\")\n",
        "print(\"Creating a new dataframe for this one:\\n\")\n",
        "df1 = pd.DataFrame({\n",
        "    'Items Sold': [5, 2, 5, 4, 9],\n",
        "    'Rates': [100, 50, 60, 400, 1000]\n",
        "})\n",
        "print(f\"The new dataframe before the calculation:\\n\\n{df1}\\n\")\n",
        "df1['Income'] = df1['Items Sold'] * df1['Rates']  # Calculating income as Items Sold * Rates\n",
        "\n",
        "print(f\"The new dataframe after the calculation:\\n\\n{df1}\\n\")"
      ],
      "metadata": {
        "id": "FCUVfK1N9Q-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constriucting a DataBlock"
      ],
      "metadata": {
        "id": "ULffRHIhBhZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Key Concepts"
      ],
      "metadata": {
        "id": "NdFZX6FLKaAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before diving into the DataBlock construction, it is important to understand the two main classes used in PyTorch and FastAI to represent datasets and batches:\n",
        "\n",
        "- **Dataset**: A collection that returns a tuple of the independent variable (input) and the dependent variable (target) for a single item.\n",
        "- **DataLoader**: An iterator that provides a stream of mini-batches. Each mini-batch consists of a batch of inputs and a batch of targets.\n",
        "\n",
        "FastAI adds two additional layers on top of these:\n",
        "\n",
        "- **Datasets**: An iterator that contains both the training and validation datasets.\n",
        "- **DataLoaders**: An object that contains a training DataLoader and a validation DataLoader.\n",
        "\n",
        "A DataLoader is built on top of a Dataset to add functionalities like batching, shuffling, and parallel data loading."
      ],
      "metadata": {
        "id": "zlhQ-d1HRlB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step-by-Step Construction of a DataBlock"
      ],
      "metadata": {
        "id": "sdIYpoN8R2gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **1. Starting Simple: DataBlock With No Parameters**\n",
        "\n",
        "---\n",
        "We begin my creating an empty ```DataBlock``` object with no parameters. This serves as the foundation for building the DataBlock step by step."
      ],
      "metadata": {
        "id": "_nrIokrdR6OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dblock = DataBlock()"
      ],
      "metadata": {
        "id": "BLmnqzYrSanN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create a ```Datasets``` object from this ```DataBlock```. The only required argument is the data source—in this case, a **DataFrame**."
      ],
      "metadata": {
        "id": "WjQ_rOkTSfhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dsets = dblock.datasets(df)"
      ],
      "metadata": {
        "id": "emMeetWlSrdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a training and validation dataset, which can be accessed as:"
      ],
      "metadata": {
        "id": "MY64Xj0fStDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dsets.train[0]"
      ],
      "metadata": {
        "id": "BuNNdXFDSvJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the ```DataBlock``` assumes there are two items: the input (independent variable) and the target (dependent variable). This will simply return a row of the DataFrame."
      ],
      "metadata": {
        "id": "iNdId-dSSz6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **2. Specifying the Input Target with ```get_x``` and ```get_y```**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "es6Qps0CS5IC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To handle the DataFrame more effectively, we specify which columns correspond to the input and target variables using ```get_x``` and ```get_y``` functions."
      ],
      "metadata": {
        "id": "IuPSeYxSTGjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dblock = DataBlock(get_x = lambda r: r['fname'], get_y = lambda r: r['labels'])\n",
        "dsets = dblock.datasets(df)\n",
        "dsets.train[0]"
      ],
      "metadata": {
        "id": "wuGSyROxTNA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Alternatively, we can define the functions more explicitly:\n",
        "def get_x(r):\n",
        "  return r['fname']\n",
        "\n",
        "def get_y(r):\n",
        "  return r['labels']\n",
        "\n",
        "dblock = DataBlock(get_x = get_x, get_y = get_y)\n",
        "dsets = dblock.datasets(df)\n",
        "dsets.train[0]"
      ],
      "metadata": {
        "id": "A2ZX98kdTOvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although using **lambda functions** is convenient, they are not compatible with serialization. For saving models after training, it's better to use the more verbose function definitions."
      ],
      "metadata": {
        "id": "tnYjrMZbTZpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **3. Adjusting the ```get_x``` and ```get_y``` Functions:**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "X-lB3NgYM_CH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moreover, we need convert the independent variable to the complete path so that we can open it as an image, and dependent variable will need to be split on the space character, so that it becomes a list."
      ],
      "metadata": {
        "id": "8Hp2J5XPTek8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Diffrent returns this time\n",
        "\n",
        "def get_x(r):\n",
        "  return path/'train'/r['fname']\n",
        "\n",
        "def get_y(r):\n",
        "  return r['labels'].split(' ')\n",
        "\n",
        "dblock = DataBlock(get_x= get_x, get_y= get_y)\n",
        "dsets = dblock.datasets(df)\n",
        "dsets.train[0]"
      ],
      "metadata": {
        "id": "v1y65amUL1aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **4. Defining The Block Types**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DxCTF7vmMVjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now need to specify the block types. Block types define how the data is processed into the correct format. For images, we use ```ImageBlock``` for the input and ```MultiCategoryBlock``` for the output, since we are doing multi-label classification."
      ],
      "metadata": {
        "id": "YYc_L4L-NTpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dblock = DataBlock(blocks= (ImageBlock, MultiCategoryBlock),\n",
        "                   get_x= get_x, get_y= get_y)\n",
        "dsets= dblock.datasets(df)\n",
        "dsets.train[0]"
      ],
      "metadata": {
        "id": "FYpkAuktNda_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note: ```TensorMultiCategory``` in output represents the multi-label format where a 1 indicates that a particular category is present for that item (similar to one-hot encoding)."
      ],
      "metadata": {
        "id": "ChStdlXeN2bA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **5. One-Hot Encoding**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oPcBBmmxORRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In multi-label classification, we use one-hot encoding to represent labels."
      ],
      "metadata": {
        "id": "TXV0vwg3Oafo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ We can get the actual labels using torch.where function\n",
        "\n",
        "idxs = torch.where(dsets.train[0][1]==1.)[0]\n",
        "dsets.train.vocab[idxs]"
      ],
      "metadata": {
        "id": "yTb00Pc3Oqk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>\n",
        "      Explaining the code snippet:\n",
        "    </b>\n",
        "  </summary>\n",
        "<ul>\n",
        "  <li>\n",
        "  <Code>dsets.train[0][1]</code>: Here <code>dests.train[0]</code> part gets the first training example and the <code>[1]</code> part gets the label or target associated with that example.\n",
        "  </li>\n",
        "  <li>\n",
        "  <code>torch.where(...)[0]</code> the <code>[0]</code> here selects the first element of the tuple returned by <code>torch.where</code>, which contains the indices of <code>True</code> elements.\n",
        "  </li>\n",
        "</ul>\n",
        "</details>"
      ],
      "metadata": {
        "id": "D1VBLPuAPJ2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **6. Handling the Validation Set**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Ujh3IlZjR0Lo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the DataBlock uses a random split to create training and validation datasets. However, we can define our own custom split by using a ```splitter``` function. This function takes the entire ```DataFrame``` and returns two lists: one for the training set and one for the validation set."
      ],
      "metadata": {
        "id": "gOHeJUFZR_hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Defining the custom splitter function\n",
        "\n",
        "def splitter(df):\n",
        "  train = df.index[~df['is_valid']].tolist()  #The ~ is used to indicate is False ie., is not valid\n",
        "  valid = df.index[df['is_valid']].tolist()\n",
        "  return train, valid\n",
        "\n",
        "## Passing the function created to the DataBlock\n",
        "\n",
        "dblock= DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
        "                  splitter= splitter,\n",
        "                  get_x= get_x, get_y= get_y)\n",
        "\n",
        "dsets = dblock.datasets(df)\n",
        "dsets.train[0]"
      ],
      "metadata": {
        "id": "bNXmVc6vSJj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **7. Creating DataLoaders**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "t_LpaexlTbs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After confirming that the individual items look correct, we now need to ensure that every item has the same size, as PyTorch requires tensors of the same shape. We can use transforms like ```RandomResizedCrop``` to resize the images."
      ],
      "metadata": {
        "id": "55F-JGjfUQaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
        "                   splitter=splitter,\n",
        "                   get_x=get_x,\n",
        "                   get_y=get_y,\n",
        "                   item_tfms=RandomResizedCrop(128, min_scale=0.35))\n",
        "dls = dblock.dataloaders(df)"
      ],
      "metadata": {
        "id": "9CGazUe7UXcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Showing the batches\n",
        "dls.show_batch(nrows=1, ncols=4)"
      ],
      "metadata": {
        "id": "aSt-OyA3UpIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **8. Debugging and Validation**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BZYMj9pWUyJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got the correct labels here. But, if anything goes wrong when creating our ```DataLoaders``` from our ```DataBlock```, we can use the ```summary()``` method to check the contents of the ```DataBlock``` and its transfromations"
      ],
      "metadata": {
        "id": "GoOZhXlMVGBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dblock.summary(df)"
      ],
      "metadata": {
        "id": "2PeRVgvUVfBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Cross Entropy"
      ],
      "metadata": {
        "id": "wVmk_Ox0Vh0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Creating the Learner\n",
        "\n",
        "learn = vision_learner(dls, resnet18)"
      ],
      "metadata": {
        "id": "tvkShYOGV97g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Creating minibatch\n",
        "x, y= to_cpu(dls.train.one_batch())\n",
        "activ = learn.model(x)\n",
        "activ.shape"
      ],
      "metadata": {
        "id": "hCo9Kq3_piSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Batch Size: 64 and  we need to calculate the probability of each of 20 categories. ---"
      ],
      "metadata": {
        "id": "5V7u22YVqI9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Checking  one of the entries\n",
        "activ[0]"
      ],
      "metadata": {
        "id": "xO2Zfp_pqwIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tensors are everywhere. So scaling them in between 0 to 1."
      ],
      "metadata": {
        "id": "x12QMyVNq5bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Using Sigmoid Function\n",
        "def binary_cross_entropy (inputs, targets):\n",
        "  inputs= inputs.sigmoid()                  ## Sigmoid activation\n",
        "  return -torch.where(targets==1, inputs, 1-inputs).log().mean()"
      ],
      "metadata": {
        "id": "e3HoZWN-rRB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>\n",
        "      The reason behind using - 've\" sign before <code>torch.where().log()</code> :\n",
        "    </b>\n",
        "  </summary>\n",
        "  Since the logarithm of a number between 0 and 1 is negative, and  we want the loss to be positive.\n",
        "\n",
        "  Also, cross entropy loss is also known as negative log-likelihood.\n",
        "\n",
        "  So, we negate the log values to get the positive loss values.\n",
        "</details>"
      ],
      "metadata": {
        "id": "TfZT6Z_Nrm5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>\n",
        "      Why not Softmax or NLLLoss?\n",
        "    </b>\n",
        "  </summary>\n",
        "  <ul>\n",
        "  <li>\n",
        "    <b>Softmax</b> requires all predictions to sum to 1, which is not ideal for multi-label classification, where we may have multiple labels for a single image.\n",
        "  </li>\n",
        "  <li>\n",
        "    <b>NLLLoss</b> works with single-label classification, where the target is a single class, but we need a method that handles multiple labels independently.\n",
        "  </li>\n",
        "  </ul>\n",
        "</details>"
      ],
      "metadata": {
        "id": "BwJgnvh_s8Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Using PyTorch Builtin BCE Loss Function\n",
        "\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "activ_tensor = activ.as_subclass(torch.Tensor)\n",
        "y_tensor = y.as_subclass(torch.Tensor)\n",
        "loss = loss_func(activ_tensor, y_tensor)\n",
        "loss"
      ],
      "metadata": {
        "id": "OU4IgeTGuV4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Metric For Multi-Label Classification:"
      ],
      "metadata": {
        "id": "z8vht91guxQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multi-label classification, we can't use the standard accuracy metric because we might have multiple labels for each input. Here's a modified version of the accuracy function that works for multi-label problems:"
      ],
      "metadata": {
        "id": "EpA_cXK03ELt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_multi(inp, targ, thresh= 0.5, sigmoid= True):\n",
        "  if sigmoid:           #Apply sigmoid if required\n",
        "    inp = inp.sigmoid()\n",
        "\n",
        "  return ((inp > thresh)== targ.bool()).float().mean()"
      ],
      "metadata": {
        "id": "OkBv0Oxx3Hrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>\n",
        "      How it works:\n",
        "    </b>\n",
        "  </summary>\n",
        "  <ul>\n",
        "  <li>\n",
        "  <b>Thresholding:</b> After applying the sigmoid to the activations, we need to decide which class activations are considered 1 (present) and which are 0 (absent). This is done by applying a threshold (default 0.5).\n",
        "  </li>\n",
        "  <li>\n",
        "  <b>Comparing:</b> We compare the thresholded predictions to the target labels, then compute the accuracy by averaging the matches across the batch.\n",
        "  </li>\n",
        "  </ul>\n",
        "</details>"
      ],
      "metadata": {
        "id": "Zc5R2s303p7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Customizing the Threshold"
      ],
      "metadata": {
        "id": "9ONTwJGe4Q5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can modify the default threshold for the accuracy function using ```partial``` from Python’s ```functools``` to create a version of ```accuracy_multi``` with a custom threshold."
      ],
      "metadata": {
        "id": "0nFNyjrh4gXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ creating next learner with threshold\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "#@ Setting custom threshold of 0.2\n",
        "learn = vision_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))"
      ],
      "metadata": {
        "id": "KTkQagHp4qZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Training the model:\n",
        "\"Once the loss function and metrics are set up, we can train the model as:\"\n",
        "\n",
        "learn.fine_tune(3, base_lr=3e-3, freeze_epochs=4)"
      ],
      "metadata": {
        "id": "g89hZefX5GEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Validating the model : On low threshold\n",
        "learn.metrics = partial(accuracy_multi, thresh= 0.1)\n",
        "learn.validate()"
      ],
      "metadata": {
        "id": "nOHdcgcL5bkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Validating the model : On high threshold\n",
        "learn.metrics = partial(accuracy_multi, thresh= 0.99)\n",
        "learn.validate()"
      ],
      "metadata": {
        "id": "kwtxdriF53vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Finding the best threshold value\n",
        "preds, targs = learn.get_preds()\n",
        "accuracy_multi(preds, targs, thresh= 0.9, sigmoid= False)"
      ],
      "metadata": {
        "id": "d6uDQacy56sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###@ Now using this approach to find the best threshold level\n",
        "\n",
        "xs = torch.linspace(0.05, 0.9575, 35)\n",
        "accs= [accuracy_multi(preds, targs, thresh = i, sigmoid= False) for i in xs]\n",
        "plt.plot(xs, accs)"
      ],
      "metadata": {
        "id": "CeDhU-PS6lkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression\n"
      ],
      "metadata": {
        "id": "bYL2wyPM7I3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Insights:"
      ],
      "metadata": {
        "id": "5qn_CNavm07z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Models Beyond Domains:\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "SRc8sS4sn7JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fastai organizes applications by domains (vision, NLP, etc.), but models are actually defined by:\n",
        "\n",
        "- Independent Variables (inputs).\n",
        "- Dependent Variables (outputs).\n",
        "- Loss Functions.\n",
        "\n",
        "This flexibility allows crafting solutions for novel problems (e.g., image-to-text, text-to-image)."
      ],
      "metadata": {
        "id": "jNkv6EuGoBmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. **Example Problem: Image Regression**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BgRShwGtoKW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:** \\\n",
        "Predict the center of a person's face in an image (key point detection).\n",
        "\n",
        "**Output:** \\\n",
        "Two float values (row and column of the face center)."
      ],
      "metadata": {
        "id": "8v1cSJKwoXVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: Biwi Kinect Head Pose\n"
      ],
      "metadata": {
        "id": "b8y2NCqQoqnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Dataset Details\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6w9L-u8Zo081"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Contains images (```_rgb.jpg```) and corresponding pose files (```_pose.txt```).\n",
        "- Each folder represents one person; the task is to predict the center of the head."
      ],
      "metadata": {
        "id": "Wi_wNtrUo6WF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Dataset Downloading and Exploration:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4rFu_A9vpQTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.BIWI_HEAD_POSE)\n",
        "path.ls()"
      ],
      "metadata": {
        "id": "g6YpLQXYpYzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(path/'02').ls()          ##Viewing the contents of folder '02'"
      ],
      "metadata": {
        "id": "z1IpCpZCpiv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Preping Image and Pose Data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_oRw5IYLpmW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Extracting the pose files:\n",
        "\n",
        "img_files = get_image_files(path)\n",
        "\n",
        "def img2pose(x):\n",
        "  return Path(f'{str(x)[:-7]}pose.txt')\n",
        "\n",
        "img2pose(img_files[0])"
      ],
      "metadata": {
        "id": "ADkRZ1lZqCuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Image Visualization:\n",
        "\n",
        "im = PILImage.create(img_files[0])\n",
        "im.shape"
      ],
      "metadata": {
        "id": "kGZSnBEJqidf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im.to_thumb(160)"
      ],
      "metadata": {
        "id": "x2-DsGpsqq5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4. Extracting the Key Points\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "J-ZGBNFGquWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Function to calculate the face center:\n",
        "\n",
        "cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\n",
        "\n",
        "def get_ctr(f):\n",
        "  ctr = np.genfromtxt(img2pose(f), skip_header=3)\n",
        "  c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n",
        "  c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n",
        "  return tensor([c1,c2])"
      ],
      "metadata": {
        "id": "IJnqJVyAq2Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " get_ctr(img_files[0])"
      ],
      "metadata": {
        "id": "fRg1l7SnrpBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataBlock API: Flexible Data Preparation"
      ],
      "metadata": {
        "id": "8BKCJUBir-FF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Custom Splitter:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bNj9c_ynsbSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"Ensure images of the same person don't mix between training and validation\"\n",
        "\n",
        "splitter = FuncSplitter(lambda o: o.parent.name == '13')"
      ],
      "metadata": {
        "id": "kWKoKdVksh5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Data Block Definition:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "NeQnnOpjs9qO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use ```PointBlock``` for coordinate labels, enabling augmentation on both images and coordinates"
      ],
      "metadata": {
        "id": "MQmVtCgctDlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "biwi = DataBlock(\n",
        "    blocks=(ImageBlock, PointBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=get_ctr,\n",
        "    splitter=splitter,\n",
        "    batch_tfms=[*aug_transforms(size=(240, 320)), Normalize.from_stats(*imagenet_stats)]\n",
        ")"
      ],
      "metadata": {
        "id": "dzT9LD9MtJF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Data Loaders:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SRxnLq35tKjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = biwi.dataloaders(path)\n",
        "dls.show_batch(max_n = 9, figsize= (8,6))"
      ],
      "metadata": {
        "id": "hztAwDJntQ-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training:"
      ],
      "metadata": {
        "id": "QtHIvrUPtccj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Understanding the Data Shapes:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "H9A179AZt5qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Mini Batches Shapes\n",
        "xb, yb = dls.one_batch()\n",
        "xb.shape, yb.shape"
      ],
      "metadata": {
        "id": "fVULQhzpuXx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##! Checking the file\n",
        "\n",
        "yb[0]"
      ],
      "metadata": {
        "id": "A8fCiZAfdEzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Learner Setup\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vDlwiC0gdO6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Using a pretrained ResNet Model for transfer Learning\n",
        "\n",
        "learn = vision_learner(dls, resnet18, y_range=(-1,1))"
      ],
      "metadata": {
        "id": "WigKl-MfdW1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Loss Function\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kWhTL3Z3djsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Default:** Mean Squared Error (MSE)\n",
        "- Predicts values close to the true coordinates.\n",
        "- Alternative: Pass a custom loss function using `loss_func` in `vision_learner`."
      ],
      "metadata": {
        "id": "mjJg-9OJdokI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4. Finding and Setting Learning Rate\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AzgED0mUeAJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.lr_find()"
      ],
      "metadata": {
        "id": "l4LzIWMSeIqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4SGNaaMJeLn7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}