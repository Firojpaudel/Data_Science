{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNro/lhvFBxeCs7d1J68tQq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Firojpaudel/Machine-Learning-Notes/blob/main/Practical%20Deep%20Learning%20For%20Coders/Chapter_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Digit Classifier"
      ],
      "metadata": {
        "id": "Gab4QLczJMyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First initializing the notebook\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "-LC0cV5JKjJp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "metadata": {
        "id": "B99rJS3-K8VD",
        "outputId": "0feb8293-76ae-4b23-d0f9-c52ebe015f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/719.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/719.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m716.8/719.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/472.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "from fastbook import *"
      ],
      "metadata": {
        "id": "ULkEpbTWMO8s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lesson 1:** How images are represented in a computer:"
      ],
      "metadata": {
        "id": "UcsxnU8YJaUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the initial learning, I'm just creating a model that classifies any image as *3 or 7*. Before that, downloading a sample of MNIST that contains images of just these digits"
      ],
      "metadata": {
        "id": "fK5ZmDN-KBE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "pCw6qVKiMBfk",
        "outputId": "bee30170-6ff8-4d53-c3ae-f97917d86b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.14% [3219456/3214948 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the directory\n",
        "path.ls()"
      ],
      "metadata": {
        "id": "3T116VSEMIjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking what's inside the training set\n",
        "(path/'train').ls()"
      ],
      "metadata": {
        "id": "8UbhnRajMoUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, yeah! there are images of 7 and 3 in the training set. The images inside these folders are labelled accordingly."
      ],
      "metadata": {
        "id": "cFt0Xp64M3N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Taking a look in these folders to check the images.\n",
        "three = (path/'train'/'3').ls().sorted()\n",
        "seven= (path/'train'/'7').ls().sorted()"
      ],
      "metadata": {
        "id": "8Ie3OEynNIMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "three"
      ],
      "metadata": {
        "id": "31BAYZ4wNbGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seven"
      ],
      "metadata": {
        "id": "icgyMIMiNsFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "They are all full of .png files.\n"
      ],
      "metadata": {
        "id": "42t_z8kQNtgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Taking a look at one of them\n",
        "img3 = Image.open(three[0])\n",
        "img3"
      ],
      "metadata": {
        "id": "0OB9Yu9mN3a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In computer as we know all data is represented as a number, we have to convert the images into an array or tensor before model training."
      ],
      "metadata": {
        "id": "evzSxUO0OINt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Converting to array\n",
        "array(img3)\n",
        "\n",
        "'''\n",
        "This is similar to doing:\n",
        "array = np.array(img3)\n",
        "array\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Ig8m-HGtO1oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Side learnings:\n",
        "#@ If we wish to see the array from particular index in both rows and columns, we could do like:\n",
        "np.array(img3)[4:10,4:10]"
      ],
      "metadata": {
        "id": "5Y9iqiw8PTZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now, in pytorch, it's kinda different. We have tensors instead of arrays\n",
        "tensor(img3)[4:10, 4:10]"
      ],
      "metadata": {
        "id": "qMMoSaVKQHVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, we could do sth like color coding in pandas."
      ],
      "metadata": {
        "id": "cxzcgcEoQvJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Visualizing in pandas\n",
        "df= pd.DataFrame(tensor(img3)[3:13, 9:19])\n",
        "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
      ],
      "metadata": {
        "id": "uFE-kt4vRGlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **First Try:** Pixel Similarity\n"
      ],
      "metadata": {
        "id": "pVFya2ZkS4n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step1: Would be to get the average of pixel values for each of our two groups"
      ],
      "metadata": {
        "id": "1QVF3xehRYh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Creating tensors containg a single image\n",
        "seven_tensors = [tensor(Image.open(o)) for o in seven]\n",
        "three_tensors = [tensor(Image.open(o)) for o in three]\n",
        "\n",
        "#@ Checking the lengths of these created tensors\n",
        "len(three_tensors), len(seven_tensors)"
      ],
      "metadata": {
        "id": "gMq-lxRlTkXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! Just checking the tensor:\n",
        "show_image(three_tensors[4])"
      ],
      "metadata": {
        "id": "l2UYh6nnUQIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Now stacking\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "stacked_threes = torch.stack(three_tensors).float()/255\n",
        "\n",
        "#@ Checking the Shape\n",
        "stacked_threes.shape"
      ],
      "metadata": {
        "id": "2sCKWVkbWpIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The meaning of this output:**<br>\n",
        "It's trying to say that we have 6,131 images, each of size 28×28 pixels.\n"
      ],
      "metadata": {
        "id": "m3MhGbluZW4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>The reason behind converting to float and dividing by 255</b>\n",
        "  </summary>\n",
        "- Some of the operations in PyTorch, such as taking means, require us to cast our integer types into float types. So, converting the stacks to float as well.<br>\n",
        "- When converted to float, the pixel values are also expected to be in between 0 to 1. So dividing by 255.  \n",
        "</details>"
      ],
      "metadata": {
        "id": "3LKm1qwUXfT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Gettig the rank of the tensor\n",
        "len(stacked_threes.shape)\n",
        "\n",
        "'''\n",
        "This is similar to doing:\n",
        "stacked_threes.shape\n",
        "'''\n"
      ],
      "metadata": {
        "id": "fQvNV_SwhooD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Ranks defined**:\n",
        "\\- Here's what the rank of tensors mean:\n",
        "  - **Rank 0**= Scalar, *real number or constant*\n",
        "  - **Rank 1**= Vector, *can be represente as list of values*\n",
        "  - **Rank 2**= Matrix, *to represent 2D data structures*\n",
        "  - **Rank 3**= 3D Tensor, *cube or stack of matrices*\n",
        "  - **Rank 4**= 4D Tensor, *to represent images in batch form: where the 4th dimension reprents the batch size*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vIdyTTHTiB0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Now computing the mean and looking at what we should be expecting for peak image for 3 (for classification)\n",
        "mean3 = stacked_threes.mean(0)\n",
        "show_image(mean3)"
      ],
      "metadata": {
        "id": "DKzESfbbjUwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Doing the same for seven\n",
        "mean7 = stacked_sevens.mean(0)\n",
        "show_image(mean7)"
      ],
      "metadata": {
        "id": "DMKMlLW0kgnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Just picking an arbitary 3s or 7s and seeing how far are we from the \"ideal digits\"\n",
        "arb_3 = stacked_threes[1]\n",
        "show_image(arb_3)\n",
        "\n",
        "arb_7 = stacked_sevens[1]\n",
        "show_image(arb_7)"
      ],
      "metadata": {
        "id": "--0N6CYWk8L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    Measuring the distances:\n",
        "  </summary>\n",
        "- Take the mean of absolute value of differences. Also called as <i>L1 Norm</i> <br>\n",
        "- Then find the Root Mean Sqaured Error (RMSE). Also called as <i>L2 Norm</i>\n",
        "</details>"
      ],
      "metadata": {
        "id": "gNNjTNZzlmTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Implementing the above information\n",
        "\n",
        "dist_3_abs = (arb_3 - mean3).abs().mean() #L1 Norm\n",
        "dist_3_sqr = ((arb_3 - mean3)**2).mean().sqrt() #L2 Norm\n",
        "dist_3_abs, dist_3_sqr"
      ],
      "metadata": {
        "id": "GQjHhZc9m1m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_7_abs= (arb_7 - mean7).abs().mean()\n",
        "dist_7_sqr= ((arb_7 - mean7)**2).mean().sqrt()\n",
        "dist_7_abs, dist_7_sqr"
      ],
      "metadata": {
        "id": "MAPOX73nnfGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Now implementing the same using loss functions.\n",
        "import torch.nn.functional as F\n",
        "\n",
        "F.l1_loss(arb_3.float(), mean3), F.mse_loss(arb_3, mean3).sqrt() #l1 stands for L1 Norm and mse is just L2 Norm"
      ],
      "metadata": {
        "id": "2mtwSBX7oKNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Numpy Arrays and PyTorch tensors"
      ],
      "metadata": {
        "id": "Z77D01FQonPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, this part it's just a revision about what Numpy arrays and tensors are."
      ],
      "metadata": {
        "id": "kelUWdR7SZO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>Why use Numpy arrays?</b>\n",
        "  </summary>\n",
        "Since they are built using optimized C code, Numpy arrays are way way faster than the python code.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "  <summary>\n",
        "    <b>Why PyTorch Tensors?</b>\n",
        "  </summary>\n",
        "They do the same task as Numpy array. Just more specified with GPUs.\n",
        "</details>"
      ],
      "metadata": {
        "id": "-djP9FaAStQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Showing in code:\n",
        "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "tnsr = torch.tensor(data)\n",
        "ary= np.array(data)"
      ],
      "metadata": {
        "id": "TiNhFZqwTksm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tnsr"
      ],
      "metadata": {
        "id": "7tGV2MvHVnpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ary"
      ],
      "metadata": {
        "id": "lI56tN6nVpUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Performing just basic drills:\n",
        "print(f\"Tensor's shape: {tnsr.shape}\")\n",
        "print(f\"Accessing 1st row of tensor: {tnsr[0]}\")\n",
        "print(f\"Accessing 2st column of tensor: {tnsr[:, 1]}\")"
      ],
      "metadata": {
        "id": "XJRf0GcLVqiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!! More drillings further:\n",
        "print(\"Sliced displays:\")\n",
        "print(f\"Accessing the 1st row 2nd column value: {tnsr[0, 1]}\")\n",
        "print(f\"Accessing the 1st rows 2nd and 3rd column values: {tnsr[0, 1:3]}\") #Here, for a:b the output would be only till a to b-1"
      ],
      "metadata": {
        "id": "Eh03QgjHWa7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Just lookig at the tensor type\n",
        "print(f\"The tensor's type: {tnsr.type()}\")\n",
        "print(f\"The datatype of this tensor: {tnsr.dtype}\")"
      ],
      "metadata": {
        "id": "0Uuf7RDKXDTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Comuptations in tensor is simple:\n",
        "print(f\"The mean of tensor is: {tnsr.float().mean()}\") #As mentioned earlier, means can't be calculated until and unless its float datatype\n",
        "print(f\"Multiplying the tensor with 0.01 we get: {tnsr*0.01}\")"
      ],
      "metadata": {
        "id": "oY7BUkQUX-FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Computing Metrics Using Broadcasting"
      ],
      "metadata": {
        "id": "jz5HMZMtY0t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating the valid set tensors\n",
        "valid_3_tnsr = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
        "valid_3_tnsr = valid_3_tnsr.float()/255\n",
        "valid_7_tnsr = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()])\n",
        "valid_7_tnsr = valid_7_tnsr.float()/255\n",
        "\n",
        "#@ Checking their shapes\n",
        "print(f\"Shape of valid 3s: {valid_3_tnsr.shape}\")\n",
        "print(f\"Shape of valid 7s: {valid_7_tnsr.shape}\")"
      ],
      "metadata": {
        "id": "oJENjjTPZVOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Function for calculating MAE:\n",
        "def mnist_distance(a, b):\n",
        "    return (a-b).abs().mean((-1, -2)) #!! Tells PyTorch that we want to take the mean ranging over values indexed by last two axes of tensor.\n",
        "\n",
        "mnist_distance(arb_3, mean3)"
      ],
      "metadata": {
        "id": "1he3HKqEcIKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Implementing MAE on the valid sets:\n",
        "valid_3_dist = mnist_distance(valid_3_tnsr, mean3)\n",
        "valid_3_dist, valid_3_dist.shape"
      ],
      "metadata": {
        "id": "i0UjP77ZexlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "    <b>The concept of broadcasting </b>\n",
        "  </summary>\n",
        "Broadcasting is a powerful feature in PyTorch that allows you to perform operations on tensors of different shapes without explicitly reshaping them. Here's a breakdown of how it works:<br>\n",
        "When we perform an operation between two tensors of different ranks (dimensions), PyTorch automatically expands the smaller tensor to match the shape of the larger tensor. <i>This process is called broadcasting</i>. It simplifies tensor operations and makes the code more concise.\n",
        "</details>"
      ],
      "metadata": {
        "id": "tDPAXb4vfXhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Simple example to illustrate broadcasting:\n",
        "\n",
        "##! Performing calculations in normal operations:\n",
        "a = torch.tensor([10., 6, -4]) #Tensor of shape 3\n",
        "b = torch.tensor([2., 8, 7])   #Tensor of shape 3\n",
        "print(\"The normal operation a+b:\", a + b)\n",
        "\n",
        "##! Changing the shape of tensor a:\n",
        "a= torch.tensor(1)\n",
        "print(\"After changing the shape of tensor a: \", a.ndim)\n",
        "print(\"We got the rank of a to be scalar\")\n",
        "print(\"Checking the rank of unchanged tensor b: \", b.ndim)\n",
        "print(\"And b is of rank 1 which is vector.\")"
      ],
      "metadata": {
        "id": "-RpUHacMg4Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So theoritically, we should not be able to perform operations between scalars and vectors. **But that's where broadcasting kicks in.**"
      ],
      "metadata": {
        "id": "aakq-ShgjIWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Seeing broadcasting in action:\n",
        "res = a+b #Broadcasting in the backend of PyTorch\n",
        "print(\"So adding two gives:\",res)"
      ],
      "metadata": {
        "id": "UrWkttSKjc2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>\n",
        "      <b>Why is this effecient anyway? </b>\n",
        "  </summary>\n",
        "Broadcasting is efficient because PyTorch doesn't actually copy the smaller tensor multiple times. Instead, it pretends the tensor has the larger shape and performs the operation in a highly optimized manner, often in C or CUDA for GPUs. This makes tensor operations both expressive and performant.\n",
        "</details>"
      ],
      "metadata": {
        "id": "gvAAIUGbkTn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Using this concept to figure out whether an image is 3 by using the following logic:\n",
        "def is_3(x):\n",
        "    return mnist_distance(x, mean3) < mnist_distance(x, mean7)\n",
        "\n",
        "print(is_3(arb_3), is_3(arb_3).float())\n",
        "\n",
        "print(\"The float value of 1.0 here means True\")"
      ],
      "metadata": {
        "id": "6MSQO81SpOYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Thanks to broadcasting, we can also test it on the full validation set of 3s\n",
        "is_3(valid_3_tnsr)"
      ],
      "metadata": {
        "id": "Rn7hRzT1qRql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now calculating accuracies\n",
        "accuracy_3= is_3(valid_3_tnsr).float().mean()\n",
        "accuracy_7= is_3(valid_7_tnsr).float().mean()\n",
        "accuracy_3, accuracy_7"
      ],
      "metadata": {
        "id": "PYuqtyOjqoyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, for the function `is_3()` the `valid_3_tenr` gave the probability value closer to 1 meaning the accuracy is valid. Now testig the same for `def is_7()`"
      ],
      "metadata": {
        "id": "bYrJMsHDq-1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Back to 7\n",
        "def is_7(x):\n",
        "    return mnist_distance(x, mean7) < mnist_distance(x, mean3)\n",
        "\n",
        "is_7(arb_7), is_7(arb_7).float()"
      ],
      "metadata": {
        "id": "MH8u6lNurYUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_7s = is_7(valid_7_tnsr).float().mean()\n",
        "accuracy_7s"
      ],
      "metadata": {
        "id": "f9-W7VJGrj-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ But turns out we don't need to test this way:\n",
        "#@ If we know the concept of probability, the sum total is always 1. So we could do like\n",
        "accuracy_7 = (1 - is_3(valid_7_tnsr).float()).mean()\n",
        "accuracy_7"
      ],
      "metadata": {
        "id": "KqBOlEjSr_uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Second Try**: SGD"
      ],
      "metadata": {
        "id": "fz16o6KHZyRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of trying to find the similarity between an image and an \"ideal image\", we could look at each individual pixel and come up with a set of weights for each, such that the highest weights are associated with those pixels most likely be black for a particular category."
      ],
      "metadata": {
        "id": "zs2nKxpcZ42d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ First going with a simpler most basic approach:\n",
        "\n",
        "def f(x):                     #!! Initializing the function\n",
        "  return x**2\n",
        "\n",
        "#!! Calculating gradients\n",
        "xt = tensor(3.).requires_grad_()\n",
        "yt= f(xt)\n",
        "print(yt)\n",
        "yt.backward()                 #!! back prop  ---> Calculating the derivative of each layer\n",
        "xt.grad\n",
        "print(\"The value of backprop is:\",xt.grad)"
      ],
      "metadata": {
        "id": "1EclgRFV6Y8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what we get here is the derivation with respect to xt. i.e.,\n",
        "$\\frac{\\partial y}{\\partial x} =\\frac{\\partial x^2}{\\partial x} = 2x$"
      ],
      "metadata": {
        "id": "0BDm4CCn7Aw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Now doing the same for vector arguments in the function\n",
        "xt= tensor([1., 2., 3.], requires_grad=True)\n",
        "print(\"The vector arg xt: \",xt)\n",
        "\n",
        "\n",
        "#!! Then we add sum to our function so that the function can take vectors (rank1 tensor) and return scalar\n",
        "def f(x):\n",
        "  return (x**2).sum()\n",
        "\n",
        "yt = f(xt)\n",
        "yt\n",
        "print(yt)\n",
        "yt.backward()\n",
        "xt.grad\n",
        "print(\"The values become:\", xt.grad)"
      ],
      "metadata": {
        "id": "ik5TWrbB9nlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert the function to machinne learning classifier, we perform the following steps:\n",
        "\n",
        "1.   Initialize the weights.\n",
        "2.   List item\n"
      ],
      "metadata": {
        "id": "IQVXSfQkuKKr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EKrd4FGSAMtu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}